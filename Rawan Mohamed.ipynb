{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install torchvision\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CO0_eqNhguJY",
        "outputId": "e1357c94-9267-465f-f2bd-2512dc46e975"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.5.1+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.1->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.1->torchvision) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPOogkjxczv8",
        "outputId": "92733cf0-1ab3-49ff-9682-6933bddea6ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] | D Loss: 0.5513 | G Loss: 1.6891\n",
            "Epoch [2/10] | D Loss: 0.8333 | G Loss: 5.7554\n",
            "Epoch [3/10] | D Loss: 0.2645 | G Loss: 2.4879\n",
            "Epoch [4/10] | D Loss: 0.6480 | G Loss: 1.0492\n",
            "Epoch [5/10] | D Loss: 0.4894 | G Loss: 1.7415\n",
            "Epoch [6/10] | D Loss: 0.5301 | G Loss: 1.9277\n",
            "Epoch [7/10] | D Loss: 0.6832 | G Loss: 3.6620\n",
            "Epoch [8/10] | D Loss: 0.8068 | G Loss: 1.4979\n",
            "Epoch [9/10] | D Loss: 0.7813 | G Loss: 1.8743\n",
            "Epoch [10/10] | D Loss: 0.8428 | G Loss: 1.4181\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, noise_dim, img_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(noise_dim, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(1024, img_dim),\n",
        "            nn.Tanh()  #range [-1, 1]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, img_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(img_dim, 1024),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()  #range [0, 1]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "#hyperparameters\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "noise_dim = 100\n",
        "img_dim = 28 * 28\n",
        "batch_size = 128\n",
        "epochs = 10\n",
        "lr = 0.0002\n",
        "\n",
        "#load dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])\n",
        "mnist = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "dataloader = DataLoader(mnist, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "#initialize the models\n",
        "generator = Generator(noise_dim, img_dim).to(device)\n",
        "discriminator = Discriminator(img_dim).to(device)\n",
        "\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "#loss function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "#training\n",
        "for epoch in range(epochs):\n",
        "    for real_imgs, _ in dataloader:\n",
        "        real_imgs = real_imgs.view(-1, img_dim).to(device)  #flatten images\n",
        "        batch_size = real_imgs.size(0)\n",
        "\n",
        "        real_labels = torch.ones(batch_size, 1).to(device)\n",
        "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
        "\n",
        "        # ---------------------\n",
        "        optimizer_D.zero_grad()\n",
        "        #loss\n",
        "        real_loss = criterion(discriminator(real_imgs), real_labels)\n",
        "        #do fake images\n",
        "        noise = torch.randn(batch_size, noise_dim).to(device)\n",
        "        fake_imgs = generator(noise)\n",
        "        #loss\n",
        "        fake_loss = criterion(discriminator(fake_imgs.detach()), fake_labels)\n",
        "        #total loss and backprop\n",
        "        d_loss = real_loss + fake_loss\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # -----------------\n",
        "        optimizer_G.zero_grad()\n",
        "        #do fake images and calculate loss\n",
        "        fake_imgs = generator(noise)\n",
        "        g_loss = criterion(discriminator(fake_imgs), real_labels)  #want the generator to fool the discriminator\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}] | D Loss: {d_loss.item():.4f} | G Loss: {g_loss.item():.4f}\")\n",
        "\n",
        "    #do and save sample images\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        with torch.no_grad():\n",
        "            sample_noise = torch.randn(16, noise_dim).to(device)\n",
        "            generated_imgs = generator(sample_noise).view(-1, 1, 28, 28)\n",
        "            save_path = f\"./gan_sample_epoch_{epoch+1}.png\"\n",
        "            torchvision.utils.save_image(generated_imgs, save_path, nrow=4, normalize=True)\n"
      ]
    }
  ]
}